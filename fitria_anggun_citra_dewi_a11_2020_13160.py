# -*- coding: utf-8 -*-
"""Fitria Anggun Citra Dewi_A11.2020.13160.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UwHmigAAQdwZ_e7TvWwRaHfpH6rAoNkO
"""

import pandas as pd
import numpy as np

dir = 'hungarian.data'
with open(dir, encoding='Latin1') as file:
  lines = [line.strip() for line in file]

lines[0:10]

import itertools
data = itertools.takewhile(
    lambda x: len(x) == 76,
    (' '.join(lines[i:(i +10)]).split() for i in range(0, len(lines), 10))
)

dir = pd.DataFrame.from_records(data)

dir.head()

dir.replace('-9', np.nan, inplace=True)
dir.head()

df_selected = dir.iloc[:, [2,3,8,9,11,15,18,31,37,39,40,43,50,57]]

df_selected.head()

column_mapping = {
    2: 'age',
    3: 'sex',
    8: 'cp',
    9: 'trestbps',
    11: 'chol',
    15: 'fbs',
    18: 'restecg',
    31: 'thalach',
    37: 'exang',
    39: 'oldpeak',
    40: 'slope',
    43: 'ca',
    50: 'thal',
    57: 'target'
}

df_selected.rename(columns=column_mapping, inplace=True)
df_selected.head()

df_selected.isnull().sum()

df_selected.loc[:, df_selected.isnull().any()].columns

df_cleaned = df_selected.dropna(thresh=len(df_selected.columns) - 100)
df_cleaned = df_selected.dropna(axis=1, thresh=len(df_selected) - 100)
df_cleaned.head()

print("All Duplicate Rows:")
df_cleaned[df_cleaned.duplicated(keep=False)]

dataClean = df_cleaned.drop_duplicates()
print("All Duplicate Rows:")
dataClean[dataClean.duplicated(keep=False)]

df_selected.info()

dataClean.info()

df = dataClean.astype(float)

df.info()

import seaborn as sns
import matplotlib.pyplot as plt

df = df.fillna(df.mean())

plot_data = df['target'].value_counts()
print(plot_data)
sns.set_theme(font_scale=1.0)
plot_data.plot(kind='bar', figsize=(7, 6), rot=0)
plt.xlabel("Status Pasien Penyakit Jantung", labelpad=14)
plt.ylabel("Jumlah", labelpad=14)
plt.title("Distribusi data status Penyakit Jantung", y=1.02);

for i, counts in enumerate(plot_data):
  plt.text(i, (counts + 1), str(counts), ha='center')

plt.show()

correlation = df.corr()
plt.figure(figsize=(12, 12))
plt.title("Heatmap Korelasi antar Fitur", y=1.02, fontdict={'size': 24})
sns.heatmap(
  correlation.round(2),
  annot = True,
  vmax = 1,
  square = True,
  cmap = 'RdYlGn_r'
)

plt.show()

df.describe()

from sklearn.model_selection import train_test_split

X = df.drop('target', axis=1).values
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

clean_classifier_nb = GaussianNB()
clean_classifier_nb.fit(X_train, y_train)

clean_classifier_dt = DecisionTreeClassifier(random_state=42)
clean_classifier_dt.fit(X_train, y_train)

clean_classifier_rf = RandomForestClassifier(n_estimators=100, random_state=42)
clean_classifier_rf.fit(X_train, y_train)

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, roc_auc_score, confusion_matrix, precision_score

def evaluation(Y_test, Y_pred):
  acc = accuracy_score(Y_test, Y_pred)
  rcl = recall_score(Y_test, Y_pred, average='weighted')
  f1 = f1_score(Y_test, Y_pred, average='weighted')
  ps = precision_score(Y_test, Y_pred, average='weighted')

  metric_dict = {
    'accuracy': round(acc, 3),
    'recall': round(rcl, 3),
    'F1 score': round(f1, 3),
    'Precision score': round(ps, 3)
  }

  return print(metric_dict)

y_pred_nb = clean_classifier_nb.predict(X_test)

# Evaluate the Gaussian NB model
print("\nGaussian NB Model:")
accuracy_nb = round(accuracy_score(y_test, y_pred_nb), 3)
print("Accuracy:",accuracy_nb)
print("Classification Report:")
print(classification_report(y_test, y_pred_nb))

evaluation(y_test, y_pred_nb)

y_pred_dt = clean_classifier_dt.predict(X_test)

# Evaluate the Decision Tree model
print("\nDecision Tree Model:")
accuracy_dt = round(accuracy_score(y_test, y_pred_dt), 3)
print("Accuracy:", accuracy_dt)
print("Classification Report:")
print(classification_report(y_test, y_pred_dt))

evaluation(y_test, y_pred_dt)

y_pred_rf = clean_classifier_rf.predict(X_test)

# Evaluate the Random Forest model
print("\nRandom Forest Model:")
accuracy_rf = round(accuracy_score(y_test, y_pred_rf), 3)
print("Accuracy:", accuracy_rf)
print("Classification Report:")
print(classification_report(y_test, y_pred_rf))

evaluation(y_test, y_pred_rf)

model_comp = pd.DataFrame({
  'Model': ['Naive Bayes', 'Decision Tree', 'Random Forest'],
  'Accuracy': [accuracy_nb*100, accuracy_dt*100, accuracy_rf*100]
})

# Membuat bar plot dengan keterangan jumlah
fig, ax = plt.subplots()
bars = plt.bar(model_comp['Model'], model_comp['Accuracy'], color=['red', 'green', 'blue'])
plt.xlabel('Model')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy for each model')
plt.xticks(rotation=45, ha='right')  # Untuk memutar label sumbu x agar lebih mudah dibaca

# Menambahkan keterangan jumlah di atas setiap bar
for bar in bars:
  yval = bar.get_height()
  plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')

plt.show()

cm = confusion_matrix(y_test, y_pred_nb)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title('Confusion Matrix')
plt.xlabel('True')
plt.ylabel('Predict')
plt.show()

from imblearn.over_sampling import SMOTE

X = df.drop(columns=['target'])
y = df['target']

smote = SMOTE(random_state=42)

# Resampling data menggunakan SMOTE
X_resampled, y_resampled = smote.fit_resample(X, y)

dataResampled = X_resampled
dataResampled['target'] = y_resampled

print("Jumlah baris data setelah resampling: {}".format(dataResampled.shape[0]))

plot_data = dataResampled['target'].value_counts()
print(plot_data)
sns.set_theme(font_scale=1.0)
plot_data.plot(kind='bar', figsize=(7, 6), rot=0)
plt.xlabel("Status Pasien Penyakit Jantung", labelpad=14)
plt.ylabel("Jumlah", labelpad=14)
plt.title("Distribusi data status Penyakit Jantung\nsetelah resampling menggunakan SMOTE", y=1.02);

for i, counts in enumerate(plot_data):
  plt.text(i, (counts + 1), str(counts), ha='center')

plt.show()

correlation = dataResampled.corr()
plt.figure(figsize=(12, 12))
plt.title("Heatmap Korelasi antar Fitur", y=1.02, fontdict={'size': 24})
sns.heatmap(
  correlation.round(2),
  annot = True,
  vmax = 1,
  square = True,
  cmap = 'RdYlGn_r'
)

plt.show()

columns_to_drop = [
  'thalach',
  'restecg',
  'fbs',
  'target'
]

X_selected = dataResampled.drop(columns_to_drop, axis=1).values
y = dataResampled['target']

X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(X_selected, y, test_size=0.3, random_state=42)

optimized_classifier_nb = GaussianNB()
optimized_classifier_nb.fit(X_train_selected, y_train_selected)

optimized_classifier_dt = DecisionTreeClassifier(random_state=42)
optimized_classifier_dt.fit(X_train_selected, y_train_selected)

optimized_classifier_rf = RandomForestClassifier(n_estimators=100, random_state=42)
optimized_classifier_rf.fit(X_train_selected, y_train_selected)

y_pred_nb_optimized = optimized_classifier_nb.predict(X_test_selected)

# Evaluate the Optimized Gaussian NB model
print("\nOptimized Gaussian NB Model:")
accuracy_nb_optimized = round(accuracy_score(y_test_selected, y_pred_nb_optimized), 3)
print("Accuracy:", accuracy_nb_optimized)
print("Classification Report:")
print(classification_report(y_test_selected, y_pred_nb_optimized))

cm = confusion_matrix(y_test, y_pred_nb)
cm_optimized = confusion_matrix(y_test_selected, y_pred_nb_optimized)

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))

sns.heatmap(cm, annot=True, fmt="d", cmap=sns.color_palette("ch:start=.2,rot=-.3", as_cmap=True), ax=ax[0])
sns.heatmap(cm_optimized, annot=True, fmt="d", cmap=sns.color_palette("ch:s=-.2,r=.6", as_cmap=True), ax=ax[1])

ax[0].set_ylabel('Predict')
ax[0].set_xlabel('True\n\nBefore Optimization')

ax[1].set_ylabel('Predict')
ax[1].set_xlabel('True\n\nAfter Optimization')

fig.suptitle("Confusion Matrix Comparation\nfor Gaussian NB Model")

plt.show()

y_pred_dt_optimized = optimized_classifier_dt.predict(X_test_selected)

# Evaluate the Optimized Decision Tree model
print("\nOptimized Decision Tree Model:")
accuracy_dt_optimized = round(accuracy_score(y_test_selected, y_pred_dt_optimized), 3)
print("Accuracy:", accuracy_dt_optimized)
print("Classification Report:")
print(classification_report(y_test_selected, y_pred_dt_optimized))

cm = confusion_matrix(y_test, y_pred_dt)
cm_optimized = confusion_matrix(y_test_selected, y_pred_dt_optimized)

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))

sns.heatmap(cm, annot=True, fmt="d", cmap=sns.color_palette("ch:start=.2,rot=-.3", as_cmap=True), ax=ax[0])
sns.heatmap(cm_optimized, annot=True, fmt="d", cmap=sns.color_palette("ch:s=-.2,r=.6", as_cmap=True), ax=ax[1])

ax[0].set_ylabel('Predict')
ax[0].set_xlabel('True\n\nBefore Optimization')

ax[1].set_ylabel('Predict')
ax[1].set_xlabel('True\n\nAfter Optimization')

fig.suptitle("Confusion Matrix Comparation\nfor Decision Tree Model")

plt.show()

y_pred_rf_optimized = optimized_classifier_rf.predict(X_test_selected)

# Evaluate the Optimized Random Forest model
print("\nOptimized Random Forest Model:")
accuracy_rf_optimized = round(accuracy_score(y_test_selected, y_pred_rf_optimized), 3)
print("Accuracy:", accuracy_rf_optimized)
print("Classification Report:")
print(classification_report(y_test_selected, y_pred_rf_optimized))

cm = confusion_matrix(y_test, y_pred_rf)
cm_optimized = confusion_matrix(y_test_selected, y_pred_rf_optimized)

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))

sns.heatmap(cm, annot=True, fmt="d", cmap=sns.color_palette("ch:start=.2,rot=-.3", as_cmap=True), ax=ax[0])
sns.heatmap(cm_optimized, annot=True, fmt="d", cmap=sns.color_palette("ch:s=-.2,r=.6", as_cmap=True), ax=ax[1])

ax[0].set_ylabel('Predict')
ax[0].set_xlabel('True\n\nBefore Optimization')

ax[1].set_ylabel('Predict')
ax[1].set_xlabel('True\n\nAfter Optimization')

fig.suptitle("Confusion Matrix Comparation\nfor Random Forest Model")

plt.show()

model_name = ['Naive Bayes', 'Decision Tree', 'Random Forest']
before_optimization = [accuracy_nb*100, accuracy_dt*100, accuracy_rf*100]
after_optimization = [accuracy_nb_optimized*100, accuracy_dt_optimized*100, accuracy_rf_optimized*100]

X_axis = np.arange(len(model_name))

bars_1 = plt.bar(X_axis - 0.2, before_optimization, 0.4, label='Before')
bars_2 = plt.bar(X_axis + 0.2, after_optimization, 0.4, label='After')

for i, counts in enumerate(before_optimization):
  plt.text(i - 0.2, (counts + 1), str(round(counts, 1)), ha='center')

for i, counts in enumerate(after_optimization):
  plt.text(i + 0.2, (counts + 1), str(round(counts, 1)), ha='center')

plt.xticks(X_axis, model_name, rotation=45, ha='right')

plt.xlabel('Model')
plt.ylabel('Accuracy (%)')
plt.title('Performance Comparation\nBefore and After Optimization')

plt.ylim(None, 119)
plt.legend()

plt.show()

"""Pada data Pasien Penyakit Jantung Hungarian, ditemukan banyak sekali nilai Null/data kosong, antara lain: 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'slope', 'ca', 'thal'. Selain itu juga ditemukan data duplikat.

Dilakukan pembersihan data untuk mengurangi nilai Null/data kosong, menghapus/drop data yang memiliki nilai Null lebih dari 100, dan menghapus data duplikat.


Setelah data dibersihkan, dilakukan permodelan menggunakan 3 model(Naive Bayes, Decision Tree, dan Random Forest). Selanjutnya mengevaluasi model dan didapatkan accuracy dari setiap model: GaussianNB=0.693; Decision Tree=0.580; dan Random Forest=0,682.


Selanjutnya dilakukan optimasi model klasifikasi, resampling data menggunakan SMOTE. Setelah itu ketiga model yang digunakan tadi dioptimasi dan dibandingkan accuracy-nya dengan yang sebelum optimasi
"""